import os
import random
import cv2
import matplotlib.pyplot as plt

import detectron2
from detectron2.utils.logger import setup_logger
import logging
logger = setup_logger()

from detectron2.engine import DefaultTrainer, DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo

from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2.data.datasets import register_coco_instances

from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
from detectron2.utils.visualizer import Visualizer, ColorMode
import detectron2
from detectron2.engine import DefaultTrainer
from detectron2.evaluation import COCOEvaluator
from detectron2.utils.logger import setup_logger
import logging



######################################################################
# ---------------------------------------------------------
# ğŸ”§ 0. ì‚¬ìš©ì ì„¤ì • 
# ---------------------------------------------------------
# ì´ë¯¸ì§€ ê°€ë¡œ ì„¸ë¡œ í¬ê¸°
IMG_W = 1008
IMG_H = 760
# í´ë˜ìŠ¤ ê°œìˆ˜
CLASS_NUM  = 4
# í•™ìŠµ iter  
ITER_NUM   = 10000      
BATCH_SIZE = 16    # GPU 1ëŒ€ ê¸°ì¤€ ë°°ì¹˜ ì‚¬ì´ì¦ˆ   
######################################################################

# 16 batch ê¸°ì¤€ ë ˆí¼ëŸ°ìŠ¤ LR
BASE_LR_REF = 0.02         
# ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ
IMG_SIZE   = f"{IMG_W}x{IMG_H}"
# ë°ì´í„°ì…‹ ì´ë¦„ (split/transform ì½”ë“œì™€ ë™ì¼ í¬ë§·)
DATASET_NAME = f"dataset_DT_cls{CLASS_NUM}_{IMG_SIZE}"

# í•™ìŠµ ì´ë¦„ (output/log/weight ì´ë¦„ì— ì‚¬ìš©)
TRAIN_NAME = f"DT_cls{CLASS_NUM}_{IMG_SIZE}_iter{ITER_NUM}"

# COCO json & image ê²½ë¡œ (train/val/test ê³µí†µ prefix)
DATASET_ROOT = f"/home/elicer/train_data_split/{DATASET_NAME}"

# ì¶œë ¥ ë£¨íŠ¸
OUTPUT_ROOT = "/home/elicer/Workspace/trained_output/output"
# ì›í•˜ëŠ” ë¡œê·¸ ê²½ë¡œ ì„¤ì •
# 1) ê¸°ë³¸ detectron2 ë¡œê±°(í•™ìŠµ ì¶œë ¥ì€ ì½˜ì†”ì—ë§Œ): íŒŒì¼ ë¡œê¹… ì—†ìŒ
setup_logger()

# 2) í‰ê°€ ë¡œê·¸ë§Œ ì €ì¥í•  í´ë”/íŒŒì¼
LOG_DIR = f"/home/elicer/Workspace/train_log/{TRAIN_NAME}"
os.makedirs(LOG_DIR, exist_ok=True)

LOG_PATH = os.path.join(LOG_DIR, "eval.log")   # <- í‰ê°€ ë¡œê·¸ë§Œ ì €ì¥ë  íŒŒì¼ ì´ë¦„

# 3) Detectron2 í‰ê°€(evaluation) ì „ìš© ë¡œê±° ê°€ì ¸ì˜¤ê¸°
eval_logger = logging.getLogger("detectron2.evaluation")
eval_logger.setLevel(logging.INFO)

# 4) íŒŒì¼ í•¸ë“¤ëŸ¬ ìƒì„±
eval_file_handler = logging.FileHandler(LOG_PATH)
eval_file_handler.setFormatter(logging.Formatter("%(asctime)s | %(levelname)s | %(message)s"))

# 5) í‰ê°€ ë¡œê±°ì—ë§Œ íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€ (í•™ìŠµ ë¡œê·¸ëŠ” ì•ˆ ë“¤ì–´ê°)
eval_logger.addHandler(eval_file_handler)

# 6) í‰ê°€ ë¡œê·¸ ìƒìœ„ ì „íŒŒ ë§‰ê¸°(ì¤‘ë³µ ë°©ì§€)
eval_logger.propagate = False
# ---------------------------------------------------------
# 1. ë°ì´í„°ì…‹ ë“±ë¡ í•¨ìˆ˜
# ---------------------------------------------------------


class MyTrainer(DefaultTrainer):
    @classmethod
    def build_evaluator(cls, cfg, dataset_name, output_folder=None):
        # í›ˆë ¨ ì¤‘ê°„/ë§ˆì§€ë§‰ì— ì‚¬ìš©í•  evaluator ì •ì˜
        if output_folder is None:
            output_folder = os.path.join(cfg.OUTPUT_DIR, "inference", dataset_name)
        os.makedirs(output_folder, exist_ok=True)
        return COCOEvaluator(dataset_name, output_dir=output_folder)


def register_datasets():
    """
    train / val / test COCO ë°ì´í„°ì…‹ ë“±ë¡.
    ì‹¤í–‰ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ./dataset_... ê²½ë¡œ ì‚¬ìš©.
    """
    train_json = os.path.join(DATASET_ROOT, "train.json")
    val_json   = os.path.join(DATASET_ROOT, "val.json")
    test_json  = os.path.join(DATASET_ROOT, "test.json")

    train_img_dir = os.path.join(DATASET_ROOT, "train/images")
    val_img_dir   = os.path.join(DATASET_ROOT, "val/images")
    test_img_dir  = os.path.join(DATASET_ROOT, "test/images")

    register_coco_instances("train_parking", {}, train_json, train_img_dir)
    register_coco_instances("val_parking",   {}, val_json,   val_img_dir)
    register_coco_instances("test_parking",  {}, test_json,  test_img_dir)

    val_metadata = MetadataCatalog.get("val_parking")
    return val_metadata


# ---------------------------------------------------------
# 2. cfg ì„¤ì • í•¨ìˆ˜
# ---------------------------------------------------------
def build_cfg():
    """
    í•™ìŠµ/í‰ê°€ì— ì‚¬ìš©í•  cfg ìƒì„±.
    """
    cfg = get_cfg()

    # ì»¤ìŠ¤í…€ ì´ë¦„ ì§€ì •
    cfg.TRAIN_NAME = TRAIN_NAME
    cfg.OUTPUT_DIR = os.path.join(OUTPUT_ROOT, cfg.TRAIN_NAME)

    # config & pretrained weight ë°±ë³¸ í†µì¼ (R_50_FPN_3x)
    cfg.merge_from_file(
        "/home/elicer/sechan/detectron/detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"
    )

    # ë°ì´í„°ì…‹ ì´ë¦„ ì„¤ì •
    cfg.DATASETS.TRAIN = ("train_parking",)
    cfg.DATASETS.TEST  = ("val_parking",)

    # DataLoader
    cfg.DATALOADER.NUM_WORKERS = 2

    # Pretrained weight
    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(
        "COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"
    )

    # Batch & LR ì„¤ì •
    num_gpu = 1
    per_gpu_batch = BATCH_SIZE
    cfg.SOLVER.IMS_PER_BATCH = num_gpu * per_gpu_batch

    # 16 batch ê¸°ì¤€ BASE_LR_REFì—ì„œ ì„ í˜• ìŠ¤ì¼€ì¼
    cfg.SOLVER.BASE_LR = BASE_LR_REF * cfg.SOLVER.IMS_PER_BATCH / 16

    # í•™ìŠµ ìŠ¤ì¼€ì¤„
    cfg.SOLVER.MAX_ITER = ITER_NUM
    cfg.TEST.EVAL_PERIOD = 100
    cfg.SOLVER.CHECKPOINT_PERIOD = 1000
    # ROI Head ì„¤ì •
    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = CLASS_NUM

    # ë””ë°”ì´ìŠ¤
    cfg.MODEL.DEVICE = "cuda"   # í•„ìš” ì‹œ "cpu"

    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
    return cfg


# ---------------------------------------------------------
# 3. í•™ìŠµ í•¨ìˆ˜
# ---------------------------------------------------------
def train_model(cfg):
    """
    MyTrainer(ì»¤ìŠ¤í…€ Trainer)ë¥¼ ì´ìš©í•´ í•™ìŠµ ìˆ˜í–‰.
    """
    trainer = MyTrainer(cfg)
    trainer.resume_or_load(resume=False)
    trainer.train()
    trainer.checkpointer.save(cfg.TRAIN_NAME)
    return trainer


# ---------------------------------------------------------
# 4. val ì´ë¯¸ì§€ ëª‡ ì¥ ì‹œê°í™” í•¨ìˆ˜ (ì˜µì…˜)
# ---------------------------------------------------------
def visualize_val_samples(cfg, val_metadata, num_samples=3):
    """
    val_parking ë°ì´í„°ì…‹ì—ì„œ ëª‡ ì¥ ë½‘ì•„ ì‹œê°í™”.
    """
    dataset_dicts = DatasetCatalog.get("val_parking")
    if len(dataset_dicts) == 0:
        print("No samples in val_parking to visualize.")
        return

    predictor = DefaultPredictor(cfg)

    for d in random.sample(dataset_dicts, min(num_samples, len(dataset_dicts))):
        img = cv2.imread(d["file_name"])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        outputs = predictor(img)

        v = Visualizer(
            img,
            metadata=val_metadata,
            scale=0.5,
            instance_mode=ColorMode.IMAGE
        )
        out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

        plt.figure(figsize=(8, 6))
        plt.imshow(out.get_image())
        plt.axis("off")
        plt.title(os.path.basename(d["file_name"]))
        plt.show()


# ---------------------------------------------------------
# 5. COCO í‰ê°€ í•¨ìˆ˜ (val/test ê³µìš©)
# ---------------------------------------------------------
def evaluate_on_dataset(cfg, dataset_name, output_dir):
    """
    ì£¼ì–´ì§„ dataset_nameì— ëŒ€í•´ COCOEvaluatorë¡œ mAP í‰ê°€.
    """
    os.makedirs(output_dir, exist_ok=True)

    predictor = DefaultPredictor(cfg)

    evaluator = COCOEvaluator(dataset_name, output_dir=output_dir)
    data_loader = build_detection_test_loader(cfg, dataset_name)

    print(f"Running COCO evaluation on {dataset_name} ...")
    results = inference_on_dataset(predictor.model, data_loader, evaluator)
    print(f"COCO evaluation results for {dataset_name}:", results)
    return results


# ---------------------------------------------------------
# 6. main: ì „ì²´ ì‹¤í–‰ íë¦„
# ---------------------------------------------------------
def main():
    # 1) ë°ì´í„°ì…‹ ë“±ë¡
    val_metadata = register_datasets()

    # 2) cfg êµ¬ì„±
    cfg = build_cfg()

    # 3) í•™ìŠµ
    train_model(cfg)

    # 4) í•™ìŠµëœ ëª¨ë¸ weightë¡œ cfg ì—…ë°ì´íŠ¸
    #    (trainerê°€ ì €ì¥í•˜ëŠ” ìµœì¢… weight ì´ë¦„ì´ ì•„ë˜ì™€ ë™ì¼í•˜ë„ë¡ ë§ì¶°ì¤˜ì•¼ í•¨)
    final_weight_path = os.path.join(cfg.OUTPUT_DIR, f"{TRAIN_NAME}.pth")
    cfg.MODEL.WEIGHTS = final_weight_path
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7

    # 5) (ì˜µì…˜) val ì´ë¯¸ì§€ ì‹œê°í™”
    visualize_val_samples(cfg, val_metadata, num_samples=3)

    # 6) test_parking í‰ê°€
    inference_out_dir = os.path.join(OUTPUT_ROOT, "inference", cfg.TRAIN_NAME, "test")
    evaluate_on_dataset(cfg, "test_parking", inference_out_dir)

    # 7) TensorBoard ì•ˆë‚´
    print("\n[TensorBoard ì•ˆë‚´]")
    print(f"  ë¡œê·¸ ë””ë ‰í† ë¦¬: {cfg.OUTPUT_DIR}")
    print(f"  ëª…ë ¹ì–´: tensorboard --logdir {cfg.OUTPUT_DIR} --port 6006")


if __name__ == "__main__":
    main()

# tensorboard --logdir ./output/DT_cls6_2016x1520_iter1000 --port 6006
